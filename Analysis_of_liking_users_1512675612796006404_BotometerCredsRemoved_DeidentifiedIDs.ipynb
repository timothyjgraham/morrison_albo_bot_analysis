{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on one file \n",
    "\n",
    "list_liking_users_data_1512675612796006404 = []\n",
    "\n",
    "with open('1512675612796006404_liking_users.jsonl') as old:\n",
    "    for x in old:\n",
    "        row = json.loads(x)\n",
    "        # print(row)\n",
    "        list_liking_users_data_1512675612796006404.append(pd.DataFrame(row[\"data\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_liking_users_data_1512675612796006404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the data into one dataframe \n",
    "liking_users_1512675612796006404_df = pd.concat(list_liking_users_data_1512675612796006404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view it \n",
    "liking_users_1512675612796006404_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file\n",
    "liking_users_1512675612796006404_df.to_csv('liking_users_1512675612796006404_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Botometer analysis of accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import json\n",
    "import botometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapidapi_key = \"xxx\"\n",
    "\n",
    "twitter_app_auth = {\n",
    "    'consumer_key': 'xxx',\n",
    "    'consumer_secret': 'xxx',\n",
    "    'access_token': 'xxx',\n",
    "    'access_token_secret': 'xxx',\n",
    "  }\n",
    "\n",
    "bom = botometer.Botometer(wait_on_ratelimit=True,\n",
    "                          rapidapi_key=rapidapi_key,\n",
    "                          **twitter_app_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users_ids_1512675612796006404_likers = list(liking_users_1512675612796006404_df['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users_ids_1512675612796006404_likers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will append the results for each account to a master list\n",
    "list_1512675612796006404_likers_bot_results = []\n",
    "\n",
    "# check all account IDs\n",
    "for x in range(len(all_users_ids_1512675612796006404_likers)):\n",
    "    print(\"Checking: \" + str(all_users_ids_1512675612796006404_likers[x]) + \" ...\")\n",
    "    try:\n",
    "        list_1512675612796006404_likers_bot_results.append(bom.check_account(int(all_users_ids_1512675612796006404_likers[x])))\n",
    "    except:\n",
    "        print(\"An error occurred! Skipping.\")\n",
    "        \n",
    "print(\"How many users did we check in total:\")\n",
    "print(len(all_users_ids_1512675612796006404_likers))\n",
    "\n",
    "print(\"How many did we collect data for (i.e. who weren't suspended)\")\n",
    "print(len(list_1512675612796006404_likers_bot_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct dataframes for all users and store in master list, to then convert into dataframe\n",
    "\n",
    "user_bot_data_ALL_list = []\n",
    "\n",
    "for i in range(len(list_1512675612796006404_likers_bot_results)):\n",
    "    # produce a single dataframe for a given user, combining all relevant data \n",
    "    df1_temp = pd.DataFrame([list_1512675612796006404_likers_bot_results[i]['user']['user_data']])\n",
    "    df2_temp = pd.DataFrame([list_1512675612796006404_likers_bot_results[i]['display_scores']['english']])\n",
    "    df3_temp = pd.DataFrame([list_1512675612796006404_likers_bot_results[i]['cap']])\n",
    "\n",
    "    df1_temp['tmp'] = 1\n",
    "    df2_temp['tmp'] = 1\n",
    "    df3_temp['tmp'] = 1\n",
    "\n",
    "    df_combined1 = pd.merge(df1_temp, df2_temp, on=['tmp'])\n",
    "\n",
    "    df_combined2 = pd.merge(df_combined1,df3_temp, on=['tmp'])\n",
    "\n",
    "    df_combined2.drop('tmp', axis=1, inplace=True)\n",
    "\n",
    "    user_bot_data_ALL_list.append(df_combined2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine list of dataframes into single dataframe\n",
    "df_all_users_botometer_results = pd.concat(user_bot_data_ALL_list)\n",
    "\n",
    "df_all_users_botometer_results.rename(columns={'id_str': 'id'}, inplace=True)\n",
    "\n",
    "df_all_users_botometer_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update 10/04/22 - did 2nd collection of liking accounts as the tweet gained more likes overnight\n",
    "\n",
    "We want to ensure that the comparison with AlboMP's election-related tweet is fairer (it has more likes as it's been published longer).\n",
    "\n",
    "I collected the 2nd collection at 10:20am 10/04/2022 (AEST). Note - check how long since tweet was published. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the 2nd collection and then remove accounts that have already been analysed\n",
    "\n",
    "list_liking_users_data_1512675612796006404_2nd_collection = []\n",
    "\n",
    "with open('1512675612796006404_liking_users_2nd_collection.jsonl') as old:\n",
    "    for x in old:\n",
    "        row = json.loads(x)\n",
    "        # print(row)\n",
    "        list_liking_users_data_1512675612796006404_2nd_collection.append(pd.DataFrame(row[\"data\"]))\n",
    "        \n",
    "        \n",
    "# combine all the data into one dataframe \n",
    "liking_users_1512675612796006404_df_2nd_collection = pd.concat(list_liking_users_data_1512675612796006404_2nd_collection)\n",
    "\n",
    "# write to file\n",
    "liking_users_1512675612796006404_df_2nd_collection.to_csv('liking_users_1512675612796006404_df_1st_and_2nd_collection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to get the list of account IDs then remove those that have already been analysed\n",
    "all_users_ids_1512675612796006404_likers_2nd_collection = list(liking_users_1512675612796006404_df_2nd_collection['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_users_ids_1512675612796006404_likers_2nd_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_users_ids_1512675612796006404_likers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get difference between two lists\n",
    "def get_diff(a: list, b: list) -> list:\n",
    "    return list(set(a) ^ set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIQUE_user_ids_1512675612796006404_likers_2nd_collection = get_diff(all_users_ids_1512675612796006404_likers,all_users_ids_1512675612796006404_likers_2nd_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(UNIQUE_user_ids_1512675612796006404_likers_2nd_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will append the results for each account to a master list\n",
    "list_1512675612796006404_likers_bot_results_2nd_collection = []\n",
    "\n",
    "# check all account IDs\n",
    "for x in range(len(UNIQUE_user_ids_1512675612796006404_likers_2nd_collection)):\n",
    "    print(\"Checking: \" + str(UNIQUE_user_ids_1512675612796006404_likers_2nd_collection[x]) + \" ...\")\n",
    "    try:\n",
    "        list_1512675612796006404_likers_bot_results_2nd_collection.append(bom.check_account(int(UNIQUE_user_ids_1512675612796006404_likers_2nd_collection[x])))\n",
    "    except:\n",
    "        print(\"An error occurred! Skipping.\")\n",
    "        \n",
    "print(\"How many users did we check in total:\")\n",
    "print(len(UNIQUE_user_ids_1512675612796006404_likers_2nd_collection))\n",
    "\n",
    "print(\"How many did we collect data for (i.e. who weren't suspended)\")\n",
    "print(len(list_1512675612796006404_likers_bot_results_2nd_collection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct dataframes for all users and store in master list, to then convert into dataframe\n",
    "\n",
    "user_bot_data_ALL_list_2nd_collection = []\n",
    "\n",
    "for i in range(len(list_1512675612796006404_likers_bot_results_2nd_collection)):\n",
    "    # produce a single dataframe for a given user, combining all relevant data \n",
    "    df1_temp = pd.DataFrame([list_1512675612796006404_likers_bot_results_2nd_collection[i]['user']['user_data']])\n",
    "    df2_temp = pd.DataFrame([list_1512675612796006404_likers_bot_results_2nd_collection[i]['display_scores']['english']])\n",
    "    df3_temp = pd.DataFrame([list_1512675612796006404_likers_bot_results_2nd_collection[i]['cap']])\n",
    "\n",
    "    df1_temp['tmp'] = 1\n",
    "    df2_temp['tmp'] = 1\n",
    "    df3_temp['tmp'] = 1\n",
    "\n",
    "    df_combined1 = pd.merge(df1_temp, df2_temp, on=['tmp'])\n",
    "\n",
    "    df_combined2 = pd.merge(df_combined1,df3_temp, on=['tmp'])\n",
    "\n",
    "    df_combined2.drop('tmp', axis=1, inplace=True)\n",
    "\n",
    "    user_bot_data_ALL_list_2nd_collection.append(df_combined2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine list of dataframes into single dataframe\n",
    "df_all_users_botometer_results_2nd_collection = pd.concat(user_bot_data_ALL_list_2nd_collection)\n",
    "\n",
    "df_all_users_botometer_results_2nd_collection.rename(columns={'id_str': 'id'}, inplace=True)\n",
    "\n",
    "df_all_users_botometer_results_2nd_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine FIRST and SECOND collection dataframes\n",
    "\n",
    "df_all_users_botometer_results = df_all_users_botometer_results.append(df_all_users_botometer_results_2nd_collection, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_users_botometer_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_users_botometer_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the COMBINED data to file\n",
    "df_all_users_botometer_results.to_csv('Botometer_results_1512675612796006404_likers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write account IDs to text file \n",
    "df_all_users_botometer_results['id'].to_csv(r'1512675612796006404_likers_account_Ids', header=None, index=None, sep='\\n', mode='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the universal scores\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set a grey background (use sns.set_theme() if seaborn version 0.11.0 or above) \n",
    "sns.set(style=\"darkgrid\")\n",
    " \n",
    "fig = sns.histplot(df_all_users_botometer_results['universal'])\n",
    "\n",
    "# plt.gcf().set_size_inches(12, 8)\n",
    "plt.gcf().set_size_inches(20, 10)\n",
    "fig.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "fig.set_xlabel(\"Bot score\", fontsize = 30)\n",
    "fig.set_ylabel(\"Number of Twitter accounts\", fontsize = 30)\n",
    "plt.title(\"Botometer scores for likers of ScottMorrisonMP's tweet (tweet ID: 1512675612796006404)\", fontdict={'fontsize':20})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_users_botometer_results[df_all_users_botometer_results['universal'] > 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_all_users_botometer_results[df_all_users_botometer_results['universal'] > 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_all_users_botometer_results[df_all_users_botometer_results['universal'] > 0.95]) / len(df_all_users_botometer_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a grey background (use sns.set_theme() if seaborn version 0.11.0 or above) \n",
    "sns.set(style=\"darkgrid\")\n",
    "df = sns.load_dataset('iris')\n",
    " \n",
    "# plotting both distibutions on the same figure\n",
    "fig = sns.kdeplot(df_all_users_botometer_results['astroturf'], shade=True)\n",
    "fig = sns.kdeplot(df_all_users_botometer_results['fake_follower'], shade=True)\n",
    "fig = sns.kdeplot(df_all_users_botometer_results['financial'], shade=True)\n",
    "fig = sns.kdeplot(df_all_users_botometer_results['self_declared'], shade=True)\n",
    "fig = sns.kdeplot(df_all_users_botometer_results['spammer'], shade=True)\n",
    "\n",
    "plt.gcf().set_size_inches(12, 8)\n",
    "fig.legend(labels=['astroturf','fake_follower','financial','self_declared','spammer'])\n",
    "\n",
    "fig.set_xlabel(\"Score\", fontsize = 20)\n",
    "fig.set_ylabel(\"Density\", fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse self-declared accounts\n",
    "df_all_users_botometer_results[df_all_users_botometer_results['self_declared'] > 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df_all_users_botometer_results[df_all_users_botometer_results['universal'] > 0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
